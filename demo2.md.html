<meta charset="utf-8" lang="es">


<center style="margin-top: 350px;">
<span style="font-weight: bolder;">Procesamiento del Lenguaje de Signos</span><br>
<span style="font-weight: lighter; font-size: 35;">Fundamentos, tecnologías y retos actuales</span>
</center>

<div style="position: absolute; right: 50; top: 50; width: 25%;">
    <img src="videos/cover.gif">
</div>

<center style="margin-top: 200px;">
<span style="font-variant: small-caps; font-size: 30; color: rgb(163, 42, 42);">Claudio Bustamante, Julián M. Galindo, Víctor Ramos, J. Antonio Rodríguez </span><br>
</center>

<center style="margin-top: 100px;">
    <span style="font-style: italic; font-size: 30;">Fuente Ppal: [Including Signed Languages in Natural Language Processing](https://aclanthology.org/2021.acl-long.570) (Yin et al., ACL 2021) </span><br>
    </center>


<div style="position:fixed; display :grid; grid-template-columns: 350px 1fr ; width:100%; bottom:0; right:0; font-size: large; text-align: right; font-style: italic; font-weight: bold; color: gray; padding-right: 30px;">
    <img style="float: left;" src="logo.png" width="350px"> <div style="display:flex; justify-content: end; align-items:end;">Procesamiento del Lenguaje Natural - Máster en Lógica Computación e Inteligencia Artificial - Universidad de Sevilla </div>
</div>

---

## Overview

<div style="display: flex; justify-content: center; align-items: center;"><video src="videos/InitialDef.mp4" style="width:85%" controls></video></div>

---


# Agenda

<div style="display: grid; grid-template-columns: 1fr 1fr 1fr;">
<div>

**1. Fundamentos**

</div>
<div>

**2. Reconocimiento**


</div>
<div>

**3. Traducción** 
    
    
</div>
</div>

<div style="display: grid; grid-template-columns: 1fr 1fr 1fr;">
    <div>
    
    **4. Producción**
    
    </div>
    <div>
    
    **5. Datasets y métricas**
    
    
    </div>
    <div>
    
    **6. SLP en el marco NLP** 
        
        
    </div>
</div>


---

# Lengua de Signos - Fundamentos

---


## Aspectos generales de las lenguas signadas (I)

* Las lenguas de signos son el principal método de comunicación para las personas sordas.

<center>
    <img src="images/usoLenguaSignosEnEuropa.jpg">
</center>

---

## Aspectos generales de las lenguas signadas (II). Mitos (I)

* Existe una única lengua de signos universal, conocida por todas las personas sordas.

<div style="display: flex; justify-content: space-around; height: 50%;">
    <img src="images/Sign-languages-in-the-world-based-on-Hammarstroem-et-al-2016.png"> <img src="images/familiasLenguasSignadas.webp">
</div>

<strong>Realidad</strong>: [Lista de lenguas de signos (Wikipedia)](https://en.wikipedia.org/wiki/List_of_sign_languages)

---

## Aspectos generales de las lenguas signadas (II). Mitos (II)

* Las lenguas de signos son traducciones letra a letra de cada una de las palabras de un idioma

<div style="display: flex; justify-content: space-around; height: 45%;">
    <img src="images/aslLetters.jpg"> <img src="images/aslWords.jpeg">
</div>


<strong>Realidad</strong>: Las lenguas de signos son lenguajes naturales completos, que involucran el uso de los gestos, las manos, el cuerpo y el entorno de los signantes. 

---


## Linguística de los Lenguajes de Signos

Las lenguas de signos constan de una estructura lingüística completa que cumple con los propósitos comunicativos de todo lenguaje natural. 

<center style="color: rgb(163, 42, 42);">¡Estructura más complicada que en los lenguajes orales!</center>


* <span style="color: rgb(163, 42, 42);">Fonología</span>: concreta las unidades mínimas e incluye gestos manuales y no manuales, movimientos, etc.
    


---

## Linguística de los Lenguajes de Signos

Las lenguas de signos constan de una estructura lingüística completa que cumple con los propósitos comunicativos de todo lenguaje natural. 

<center style="color: rgb(163, 42, 42);">¡Estructura más complicada que en los lenguajes orales!</center>


* <span style="color: rgb(163, 42, 42);">Fonología</span>: concreta las unidades mínimas e incluye gestos manuales y no manuales, movimientos, etc.
    

    <center style="font-size:150; margin-top: 120px;">
        <span style="color: rgb(163, 42, 42);">C</span>ASA vs <span style="color: rgb(163, 42, 42);">T</span>ASA</div>
    </center>

---

## Linguística de los Lenguajes de Signos

Las lenguas de signos constan de una estructura lingüística completa que cumple con los propósitos comunicativos de todo lenguaje natural. 

<center style="color: rgb(163, 42, 42);">¡Estructura más complicada que en los lenguajes orales!</center>


* <span style="color: rgb(163, 42, 42);">Fonología</span>: concreta las unidades mínimas e incluye gestos manuales y no manuales, movimientos, etc.
    

<div style="display: flex; justify-content: space-around; height: 40%;">
    <img src="images/DiferenciasSignos1.gif">
</div>

---


## Linguística de los Lenguajes de Signos

Las lenguas de signos constan de una estructura lingüística completa que cumple con los propósitos comunicativos de todo lenguaje natural. 

<center style="color: rgb(163, 42, 42);">¡Estructura más complicada que en los lenguajes orales!</center>


* <span style="color: rgb(163, 42, 42);">Fonología</span>: concreta las unidades mínimas e incluye gestos manuales y no manuales, movimientos, etc.
    

<div style="display: flex; justify-content: space-around; height: 40%;">
    <img src="images/DiferenciasSignos2.gif">
</div>

---


## Linguística de los Lenguajes de Signos

Las lenguas de signos constan de una estructura lingüística completa que cumple con los propósitos comunicativos de todo lenguaje natural. 

<center style="color: rgb(163, 42, 42);">¡Estructura más complicada que en los lenguajes orales!</center>


* <span style="color: rgb(163, 42, 42);">Fonología/Morfología</span>: concreta las unidades mínimas e incluye gestos manuales y no manuales, movimientos, ... y también el <span style="color: rgb(163, 42, 42);">Deletreo con los dedos</span>

* <span style="color: rgb(163, 42, 42);">Sintaxis</span>: En cada lengua de signos la Sintaxis puede variar o incluso tener varias estructuras correctas. Especial relevancia : <span style="color: rgb(163, 42, 42);">Simultaneidad</span>

<center>
<div style="width:90%; display: grid; grid-template-columns: 1fr 1fr;">
    <div style="display: flex; flex-direction: column;">
        <div style="color: rgb(163, 42, 42);">YO NO TERMINAR LA PELÍCULA</div>
    </div> 
    <div style="display: flex; flex-direction: column;">
        <div style="color: rgb(163, 42, 42);">POR TI, PERRO MARRÓN YO RECOGER </div>
    </div> 
</div>

* <span style="color: rgb(163, 42, 42);">Semántica</span>: Establece el significado de los símbolos pero también posibles intenciones, emociones, etc. Aspecto clave: <span style="color: rgb(163, 42, 42);">Referencias</span>
</center>

--- 

## Linguística de los Lenguajes de Signos (II). Algunos aspectos clave.


<center>
    <video src="videos/vokoscreen-2022-04-24_17-44-43.mp4" style="width:55%" controls></video><br>
    <span style="font-style: italic; font-size: 20;"> Fuente: [ASL Conversation](https://www.youtube.com/watch?v=Ckccp6z_kbo) </span>
</center>

<center>
    <div style="width:90%; display: grid; grid-template-columns: 1fr 1fr 1fr;">
        <div style="display: flex; flex-direction: column;">
            <div style="color: rgb(163, 42, 42);">Simultaneidad</div>
        </div> 
        <div style="display: flex; flex-direction: column;">
            <div style="color: rgb(163, 42, 42);">Referencias</div>
        </div>
        <div style="display: flex; flex-direction: column;">
            <div style="color: rgb(163, 42, 42);">Deletreo con dedos </div>
        </div>
    </div>
    </center>

--- 

## Representación en lenguajes de signos


<center>
    <div style="width:90%; display: flex; flex-direction: column; justify-content: start;">
        <img src="images/Represent1.png">
    </div>
    </center>

---

## Representación en lenguajes de signos


<center>
    <div style="width:90%; display: flex; flex-direction: column; justify-content: start;">
        <img src="images/Represent1.png">
        <img src="images/Represent2.png">
    </div>
    </center>

---

## Representación en lenguajes de signos


<center>
    <div style="width:90%; display: flex; flex-direction: column; justify-content: start;">
        <img src="images/Represent1.png">
        <img src="images/Represent2.png">
        <img src="images/Represent3.png">
    </div>
    </center>

---

## Representación en lenguajes de signos


<center>
    <div style="width:90%; display: flex; flex-direction: column; justify-content: start;">
        <img src="images/Represent1.png">
        <img src="images/Represent2.png">
        <img src="images/Represent3.png">
        <img src="images/Represent4.png">
    </div>
</center>
    
Recursos disponibles:  <span style="color: rgb(163, 42, 42);">Diccionarios</span>, <span style="color: rgb(163, 42, 42);">Símbolos aislados</span>, <span style="color: rgb(163, 42, 42);">Deletreo manual</span>, <span style="color: rgb(163, 42, 42);">Signos continuos</span>.

        
    Un problema añadido: <span style="color: rgb(163, 42, 42);">Anonimización</span>
  

---


## Objetivos en SLP (I). Lo que tenemos...

    
<div style="display: flex; justify-content: center; align-items: center;">
    <video src="videos/Goals1.mp4" style="width:80%" controls></video> 
</div>  

---

## Objetivos en SLP (II). ¿Sueño o realidad?
<br>
<div style="display: flex; justify-content: space-around; align-items: center;">
<div><center><img src="images/goal.png" width="80%"><br>[AR + SLP for Deaf People Education](https://www.semanticscholar.org/paper/Holographic-Signing-Avatars-for-Deaf-Education-Adamo-Villani-Anasingaraju/eddfd490d4f86d60ce32cdc7d2742aeb8a6e8f4b)</center></div>

</div>  
<br>

---

## Objetivos en SLP (II). ¿Sueño o realidad?
<br>
<div style="display: flex; justify-content: space-around; align-items: center;">
<div><center><img src="images/goal.png" width="80%"><br>[AR + SLP for Deaf People Education](https://www.semanticscholar.org/paper/Holographic-Signing-Avatars-for-Deaf-Education-Adamo-Villani-Anasingaraju/eddfd490d4f86d60ce32cdc7d2742aeb8a6e8f4b)</center></div>
<div>
    
**¿Qué requeriría por parte de SLP?**

* Reconocimiento del lenguaje.
* Traducción Oral-Signado.
* Generación con Avatares.

</div>
</div>  
<br>


---

# Tareas en Lenguas de Signos I. <br> Reconocimiento y traducción

---

## Reconocimiento (SLR)

Tarea de reconocer los propios elementos discretos del lenguaje de signos, que incluye todo el proceso de seguimiento e identificación
de los signos realizados y su conversión en palabras y expresiones semánticamente significativas.


* <span style="font-weight: bold;">Tecnología</span>:  <span style="color: rgb(163, 42, 42);"> Aproximaciones basadas sólo en imagen </span> (con uso exclusivo de cámaras y procesamiento basado en Visión por Computador) / <span style="color: rgb(163, 42, 42);">Aproximaciones basadas en multi-sensores</span> (se cuenta con componentes adicionales: guantes, acelerómetros,... procesando la información de forma conjunta).

* <span style="font-weight: bold;">Objetivo</span>:  <span style="color: rgb(163, 42, 42);">Reconocimiento aislado</span> (reconocimiento de cada uno de los símbolos por separado) / <span style="color: rgb(163, 42, 42);">Reconocimiento continuo</span> (la detección y clasificación se realiza a partir de varios símbolos a través del tiempo).

--- 


## Reconocimiento. Métodos basados en visión por computador (VBA).

*  <span style="color: rgb(163, 42, 42);">Vídeo</span> como fuente para el reconocimiento.

*  Desarrollo de modelos y capacidad computacional en visión artificial en la última década: aprovechamiento de la <span style="color: rgb(163, 42, 42);">información temporal</span>.

* En general, se preprocesan las imágenes adquiridas para obtener un vector de características y se clasifica según el modelo usado.

<center>
<div style="display: flex; justify-content: space-around; margin-top: 20px;">
    <div align="left"><video src="videos/VBA_1.mp4" style="width:80%" controls></video></div>
	<div align="right"><video src="videos/VBA_2.mp4" style="width:80%" controls></video></div>
</div>  
   <span style="font-style: italic; font-size: 20;"> Fuente: [Nicholas Renotte](https://www.youtube.com/watch?v=doDUihpj6ro) </span>
</center>

--- 

## Reconocimiento. Aproximaciones basadas en guantes (GBA).

* Captura de posición, orientación y ubicación de las manos con alta precisión.

<center>
    <video src="videos/GBA.mp4" style="width:55%" controls></video><br>
    <span style="font-style: italic; font-size: 20;"> Fuente: [Tech Insider](https://www.youtube.com/watch?v=RHTrAXsULOI&ab_channel=TechInsider) </span>
</center>

--- 

## Reconocimiento. Reconocimiento Aislado vs Reconocimiento continuo

Actualmente la mayoría de los modelos de reconocimiento se dedican al reconocimiento asilado, eso es, al reconocimiento de cada signo por separado. Varias limitaciones:

* Pérdida del contexto, especialmente grave en el tratamiento de las Referencias
* Problemas de análisis temporal diferenciación de signos por movimiento: Oclusión, Tracking, ... 
* Dificultad en la integración de datos multimodal con los datos de  visión 

Nuevas líneas: <span style="color: rgb(163, 42, 42);">Análisis continuo</span>. Con gran influencia de técnicas de <u>análisis temporal</u>: Hidden Markov Models (HMM), Dynamic Time Wrapping, Conditional Random Fields (CRF), Support Vector Machines (SVM), Deep Learning (3D-CNN-LSTM, ...)

--- 

## Detección.

Tarea de clasificación binaria de cualquier fotograma dado de un vídeo que verifica si una persona está utilizando
lenguaje de signos o no.

* <span style="color: rgb(163, 42, 42);">Modelos/Paquetes</span> para la detección en SLP: OpenPose, DensePose, MediaPipe Holistic.


<center style="margin-bottom: -20px; margin-top: -20px;">
<div style=" width: 100%; display: flex; flex-direction: row; justify-content: center;">
    <img src="images/detection_2.png" style="width:45%"> 
    <img src="images/detection_1.png" style="width:42%"> 
</div> 
</center>



--- 


## Identificación.

La tarea de identificación de lenguas de signos se define como la clasificación entre dos o más lenguas de signos.

* <span style="color: rgb(163, 42, 42);">Gebre, Wittenburg y Heskes.2013</span>: un clasificador random forest simple puede distinguir entre la lengua de signos británica (BSL) y la lengua de signos griega(ENN) con F1 del 95%.

* <span style="color: rgb(163, 42, 42);">Monteiro et al. 2016</span>: Misma arquitectura. Diferencia entre la lengua de signos británica y la lengua de signos francesa con F1 de 98% de en vídeos con fondos estáticos, y entre la lengua de signos americana y británica con un 70%.


Atribuyen su éxito principalmente a los diferentes sistemas de deletreo con los dedos, que es a dos manos en el caso británico y a una mano en el caso estadounidense.


--- 


## Segmentación.

Detección de los límites de los signos en un fotograma u oraciones para dividirlos en unidades lingüísticas con significado.

* <strong>Lenguaje hablado</strong>: División en el tiempo como secuencia lineal.

<center style="color: rgb(163, 42, 42);">¡Simultaneaidad del lenguaje signado!</center>

* <strong>Lenguaje signado</strong>: Concepto de palabra difuso. Aproximación lineal insuficiente.

* <span style="color: rgb(163, 42, 42);">Farag y Brock. 2019</span>: Detección de los límites de las palabras dentro de expresiones en el lenguaje de signos japonés a partir de las posiciones tridimensionales de las articulaciones del cuerpo.

* <span style="color: rgb(163, 42, 42);">Bull, Gouiffès y Braffort. 2020</span>: Segmentación de lengua de signos francesa que han sido correctamente subtitulados a partir de la alienación de los mismo.

--- 

## Segmentación.

* <span style="color: rgb(163, 42, 42);">Gül Varol et al. 2021</span>:Mejoran las métricas obtenidas por Farag y Brock con una arquitectura que acopla una red convolucional espacio-temporal 3D (I3D) con una red convolucional temporal multietapa (1D).

<center>
    <div style="width:66%; display: flex; flex-direction: column; justify-content: start;">
        <img src="images/segmentation.png">
		<div><span style="font-style: italic; font-size: 20;"> Fuente: Gül Varol et al. 2021 </span></div>
    </div>
</center>

--- 

## Framework general.
El reconocimiento del lenguaje de signos consta de tres fases principales: 

* Segmentación de imagen y seguimiento.
* Extracción de características.
* Clasificación. 

<center>
        <img style="width: 60%;" src="images/general_framework.png"><br>
		<span style="font-style: italic; font-size: 20;"> Fuente: Subhash Chand Agrawal et al. 2016 </span>
</center>

---

## Procesamiento de características.

Las técnicas de preprocesamiento se aplican a una imagen de entrada para eliminar el ruido no deseado y también mejorar la calidad.

* <span style="color: rgb(163, 42, 42);">Técnicas de mejora</span>: ecualización del histograma (HE), la ecualización adaptativa del histograma (AHE), la ecualización adaptativa del histograma con contraste limitado (CLAHE) y la transformación logarítmica.

* <span style="color: rgb(163, 42, 42);">Técnicas de restauración</span>: filtro mediano, el filtro medio, el filtro gaussiano, el filtro adaptativo y el filtro Wiener.

---

## Procesamiento de características. Segmentación de imagen

Proceso de dividir una imagen en regiones significativas llamadas segmentos.

* <span style="color: rgb(163, 42, 42);">Contextual</span>: relaciones entre las características de la imagen, como los bordes, las intensidades similares y la proximidad espacial.

* <span style="color: rgb(163, 42, 42);">No contextual</span>: ignora relaciones espaciales. Agrupa los píxeles basándose en el valor de los atributos globales.


<center>
    <div style="width:44%; display: flex; flex-direction: column; justify-content: start;">
        <img src="images/seg_imag.png">
    </div>
</center>

---

## Procesamiento de características. Extracción de características.

Forma de reducción dimensional que representa eficazmente las partes interesantes de una imagen.

* Se extrae un vector de características compacto eliminando una parte irrelevante para aumentar la precisión del aprendizaje y mejorar la visibilidad del resultado.

* Las características extraídas de la región interesada se caracterizan por ser de color, textura, forma, etc.

* Técnicas importantes usadas en SLR: PCA, FD, HOG, SIFT, SURF

---

## Clasificación y predicción.

Las técnicas de inteligencia artificial utilizadas para el reconocimiento del lenguaje de signos incluyen el supervisado y el no supervisado.

* Predictores inteligentes más utilizados para el reconocimiento del lenguaje de signos:
	* Vecino más cercano (KNN).
	* Red neuronal artificial (ANN).
	* Supported Vector Machine (SVM).
	* Modelo de Markov oculto (HMM). 
	* Red neuronal convolucional (CNN),
	* Lógica difusa.

--- 
    
## Reconocimiento. Ejemplo

<center>
<iframe style="width: 80%; height: 60%;" src="https://fingerspelling.xyz/chooseLevel">
</iframe><br>
<span style="font-style: italic; font-size: 20;"> Fuente: <a href="https://fingerspelling.xyz" target="_blank">Fingerspelling</a></span>
</center>



---

## Traducción

La RAE lo define como: Acción y efecto de expresar en una lengua lo que está escrito o se ha expresado antes en otra.

    * En el contexto SLP: tarea de conversión del lenguajes de signos interpretados a otros lenguajes, no necesariamente de signos.
	
<center>
        <img style="width: 50%;" src="images/translation.png"><br>
		<span style="font-style: italic; font-size: 20;"> Fuente: [https://sign-language-processing.github.io/](Sign Language Processing) </span>
</center>

---

## Traducción automática (MT)

    * Invisibilización de la importancia del lenguaje de signos.
    * Planteamiento muy diferente al habitual, pues trabajamos con vídeos en lugar de con audio o texto escrito.
	
Actualmente los modelos que mejores resultados obtienen provienen de técnicas hibrídas entre los dos campos de gran desarrollo actualmente : Visión y PLN. **¡ÉSTE ES EL FUTURO DEL CAMPO!**

<center>
        <img style="width: 40%;" src="images/translation2.png"><br>
		<span style="font-style: italic; font-size: 20;"> Fuente: [Sign language transformers](https://openaccess.thecvf.com/content_CVPR_2020/papers/Camgoz_Sign_Language_Transformers_Joint_End-to-End_Sign_Language_Recognition_and_Translation_CVPR_2020_paper.pdf) </span>
    </div>
</center>

---

## Traducción: estado del arte

* <span style="color: rgb(163, 42, 42);">TSPNet (Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation).</span>
    * Consideran información temporal como añadido de cara al entrenamiento frente tratamiento frame a frame.
<center>
    <img style="width:80%;" src="images/TSPNet.png"><br>    
    <span style="font-style: italic; font-size: 20;"> Fuente: [TSPNet](https://proceedings.neurips.cc//paper/2020/file/8c00dee24c9878fea090ed070b44f1ab-Paper.pdf) </span>
</center>


---

# Tareas en Lenguas de Signos III. <br> Producción.

--- 

## Objetivo

Lograr la traducción de un lenguaje fuente, ya sea en modalidad escrita, hablada o visual 
(en caso de otros lenguajes de signos) a un flujo continuo de lenguaje de signos en un nivel
comparable al de un traductor humano.

Existen diferentes técnicas, pero generalmente se reduce al uso de alguna representación humana
a modo de un avatar. La forma de formar este avatar difiere, pudiendo generarse en base a
animaciones predefinidas por glosa, accediendo directamente al esqueleto, o incluso la Generación
completa del video sin utilizar un modelo 3D.

--- 

## Retos

Tanto el reconocimiento como la producción de signos deben enfrentar retos críticos. Uno de ellos es
la variabilidad visual de los signos, la cual es dependiente de la forma de las manos, orientación de las
palmas, movimiento, locación, expresiones faciales y otras señales no manuales.

Otro reto es el desarrollo de un sistema de SLP fotorrealista para generar el signo, palabra u oración
correspondientes en base a un texto o voz en lenguaje hablado dentro de una situación del mundo real.

La traducción desde lenguaje hablado a lenguaje de señas tomando en cuenta las reglas gramaticales
y estructuras lingüísticas del SL es un problema muy complejo. No se trata de un problema de mapeo
entre texto/voz a signos palabra por palabra, el problema surge de las diferencias entre la tokenización
y el orden de las palabras en cada lenguaje.

--- 

## Modalidades de Input

* <span style="color: rgb(163, 42, 42);">Visión</span>
En el caso de la visión, suelen utilizarse datos en formato RGB y esqueletos. 
Los datos RGB pueden ser imágenes o videos en alta resolución.

* <span style="color: rgb(163, 42, 42);">Linguística</span>
Comúnmente texto. El texto es procesado usando diferentes modelos de reconocimiento.
es fundamental especializar el sistema en un dominio en particular.
Para no comenzar desde cero, se suele utilizar transfer learning.


--- 

## Modelos Propuestos: Avatar

* <span style="color: rgb(163, 42, 42);">Qué son</span>
Técnica para mostrar una conversación de signos sin utilizar un humano, normalmente
utilizando modelos 3D animados, los cuales se pueden almacenar de manera más eficiente que videos.
Estos modelos pueden replicar el movimiento de los dedos, manos, gestos faciales y movimiento corporal.
También se puede programar para ser utilizado en conjunto con diferentes lenguajes de signos

* <span style="color: rgb(163, 42, 42);">Cómo producirlos</span>
Para formar cada movimiento del avatar, es necesaria información de captura de movimiento y glosas
parametrizadas.

* <span style="color: rgb(163, 42, 42);">No son muy aceptados en la comunidad sorda</span>

--- 

## Modelos Propuestos: Motion Graph

Motion Graph (MG) es un método de computación gráfica para animar personajes dinámicamente. 
Se define como un grafo dirigido construido a base de datos de captura de movimiento.Motion Graph (MG) es un método de computación gráfica para animar personajes dinámicamente. Se define como un grafo dirigido construido a base de datos de captura de movimiento.

Mediante un cálculo de la diferencia entre dos grafos o poses deseadas, se puede generar
la transición del modelo entre ellas.

<center>
    <span style="font-style: italic; font-size: 20;">
        Fuente: [figshare](https://figshare.com/articles/media/Signing_avatar_ratings/16877131/2?file=31206256)</span><br>
    <img style="width:58%;" src="images/motionGraph.jpg">
    </center>

--- 

## Modelos Propuestos: NMT

Las NMT son modelos que utilizan redes neuronales para predecir la probabilidad de una secuencia de palabras, 
típicamente modelando oraciones completas en un modelo integrado.

Principal ejemplo creado en base a esta técnica es Text2Sign.

<center>
    <img style="width:50%;" src="images/text2sign.png"><br>
    <span style="font-style: italic; font-size: 20;"> Fuente: [Text2Sign](https://link.springer.com/article/10.1007/s11263-019-01281-2) </span>
</center>

--- 

## Modelos Propuestos: Generación de Imagen/Video

Utilizando técnicas generativas de deep learning, con arquitecturas de redes neuronales en forma de
variable auto-encoders (VAEs) y generative adversarial networks (GANs), se pueden dejar de lado algunos
pasos de diseño y generar directamente un video.

<center>
    <div style="display: flex; justify-content: center; align-items: center; width: 60%"><video src="videos/producion.mp4" style="width:85%" controls></video></div>
</center>

--- 

# Datasets más frecuentes y Métricas

---

## Datasets más frecuentes

Destacamos primeramente la labor de Duarte et al.: 
<!-- con la creación del repositorio que
usaremos como principal referencia, en el que podemos encontrar multitud de conjuntos de datos, así
como las características de cada uno, tales como el idioma, el tamaño de los archivos, la disponibilidad...
En definitiva, con este recurso contamos con una amplia biblioteca de conjuntos de datos útiles para
el estudio del lenguaje de signos. -->

<object type="text/html" data="https://how2sign.github.io/related_datasets.html" width="100%" height="70%"></object>

--- 

## Datasets más frecuentes

* <span style="color: rgb(163, 42, 42);">RWTH-PHOENIX-Weather 2014 (Continuous Sign Language Recognition Dataset)
    y 2014 T (Parallel Corpus of Sign Language Video, Gloss and Translation).</span> <br>
    * Diseñados por Koller et al. y Camgöz et al. 
    * Generados a partir de noticieros diarios entre 2009 y 2011.
    * Lenguaje de signos alemán (GSL).
    * Canal de televisión pública PHOENIX.
    * Transcripción mixta, combinando automática (RASR) con trabajo de nativos del GSL.
    * Completado con alemán hablado para capturar la variabilidad de la traducción. 
    * 2014 T incluye anotaciones originales entre otro contenido.

--- 

## Datasets más frecuentes

<center>
    <img style="width:50%;" src="images/2014PHOENIX.png"><br>
    <span style="font-style: italic; font-size: 20;">Ejemplo de contenido de PHOENIX 2014. Porcentajes según tiempo en pantalla.</span>
</center>

--- 

## Datasets más frecuentes

* <span style="color: rgb(163, 42, 42);">AUTSL (A Large Scale Multi-Modal Turkish Sign Language Dataset and Baseline).</span><br>
    * Diseñado por Sincan y Keles.
    * Lenguaje de signos turco (TSL).
    * Objetivo: proporcionar un punto de partida desafiante.
    * 226 signos interpretados por 43 signantes diferentes.
    * 38.336 muestras aisladas de signos.
    * Complejidad: diferentes fondos, posiciones y posturas.
    * Información: RGB, profundidad y pose. 
    * ~95% de precisión en AUTSL y Montalbano, pasando a ~60% en AUTSL para una subselección.

--- 

## Datasets más frecuentes

<center>
    <img style="width:50%;" src="images/autsl.PNG"><br>
    <span style="font-style: italic; font-size: 20;">Información disponible en AUTSL.</span>
</center>

--- 

<style>
.center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 50%;
  }
</style>

## Datasets más frecuentes

<center>
    <img src="images/Dataset_Fig1_backgrounds.jpg" class="center" alt="Ejemplos"><br>
    <span style="font-style: italic; font-size: 20;">Variación de intérpretes y fondos.</span>
</center>



--- 

## Datasets más frecuentes

* <span style="color: rgb(163, 42, 42);">WLASL-2000 (Word-level Deep Sign Language Recognition from Video: A New
    Large-scale Dataset and Methods Comparison).</span> <br>
    * ASL.
    * 2.000 palabras diferentes comunes.
    * Facilitar investigación y facilitar comunicación sordos-oyentes.

* <span style="color: rgb(163, 42, 42);">LSA64 (LSA64: A Dataset for Argentinian Sign Language).</span><br>
    * Lenguaje de signos argentino (LSA).
    * 3.200 vídeos.
    * 10 intérpretes no expertos ejecutan cada uno 5 repeticiones de 64 tipos de signos.
    * Incluye verbos y sustantivos comunes

--- 

## Datasets: problemáticas

    * <span style="color: rgb(163, 42, 42);">Escasez</span>
    
    <object type="text/html" data="https://how2sign.github.io/related_datasets.html" width="100%" height="70%"></object>

--- 

## Datasets: problemáticas

    * <span style="color: rgb(163, 42, 42);">Incompletitud</span>

    <center>
        <img style="width=50%;" src="images/Contenido.PNG" class="center" alt="Ejemplos"><br>
        <span style="font-style: italic; font-size: 20;">Contenido de ASLLVD, MS-ASL, Purdue RVL-SLLL, WLASL y ASL-LEX.</span>
    </center>


--- 

## Datasets: problemáticas

    * <span style="color: rgb(163, 42, 42);">Incompatibilidad</span>

    <center>
        <img style="width=50%;" src="images/SOV.png" class="center" alt="Ejemplos">
        <span style="font-style: italic; font-size: 20;">Porcentaje de idiomas según ordenación.</span>
    </center>

---

## Datasets: problemáticas

    * <span style="color: rgb(163, 42, 42);">Anonimización</span>

    <center>
        <img style="width=50%;" src="images/strawberry.jpg" class="center" alt="Ejemplos">
        <span style="font-style: italic; font-size: 20;">Ejemplo de anonimización conservando información facial.</span>
    </center>

--- 

## Métricas utilizadas

Destacamos ahora algunas de las métricas más comúnmente empleadas al tratar con lenguajes de signos, especialmente de cara a la traducción.

    * <span style="color: rgb(163, 42, 42);">WER, Word Error Rate</span>
    * <span style="color: rgb(163, 42, 42);">BLEU</span>
    * <span style="color: rgb(163, 42, 42);">ROUGE</span>

--- 

## Métricas utilizadas: WER

WER, Word Error Rate considera el número mínimo de inserciones, borrados y sustituciones de una palabra por otra, necesarios
para transformar una frase en otra. Esta medida se basa en la distancia de edición o distancia de
Levenshtein, pasando del nivel de letra al de palabra. <br>
Es empleada principalmente en reconocimiento y traducción automáticos, comparando una frase sintética con una de referencia correcta.

--- 

## Métricas utilizadas: WER
<center>
    <img stlye="width: 10%;" src="images/WER.PNG" alt="Fórmula WER">
    <img style="width: 50%;" src="images/WER2.PNG"><br>
    <span style="font-style: italic; font-size: 20;">Ejemplo para calcular la métrica WER.</span>    
</center>


    * S es el número de sustituciones,
    * B es el número de borrados,
    * I es el número de inserciones,
    * N es el número de palabras que tiene la frase de referencia.


<center>
    
</center>

--- 


## Métricas utilizadas: BLEU-n

BLEU (Bilingual Evaluation Understudy) es un método de evaluación de la calidad de traducciones
realizadas por sistemas de traducción automática. 

    * Mide la calidad al comparar la semejanza con una frase de referencia, supuesta correcta. 
    * Admite varias frases de referencia al mismo tiempo. <!-- Traducciones libres humanas -->
    * Adaptación de la precisión en n-gramas.
    * Diseñada para analizar traducciones, pero ampliable para evaluar texto sintético.

---

## Métricas utilizadas: BLEU-n
Partimos de la precisión simple de n-gramas: <br>
<img src="images/BLEU.PNG" alt="Fórmula precisión" class="center">

Veamos un ejemplo: <br>
<img src="images/BLEU_ejemplo.PNG" alt="Ejemplo de cálculo"  class="center">

<!-- 4/6 y 3/6 en 1-gramas, 6/6 si todas fuesen the (!) -->
--- 

## Métricas utilizadas: BLEU-n
En esencia BLEU ~ media geométrica de precisiones. <br> 
<img src="images/BLEU_formula.PNG" alt="Fórmula BLEU"  class="center">
donde PB es la precisión modificada penalizada por brevedad (considérese "the the" vs. la frase anterior).
<!-- w_n pesos 1/N habitualmente, P la precisión -->


---

## Métricas utilizadas: ROUGE

ROUGE (Recall-Oriented Understudy for Gisting Evaluation) difiere de la medida BLEU en la memoria:
<center style="color: rgb(163, 42, 42); font-family: 'Lucida Console', 'Courier New', monospace;">cuánto del documento de referencia el sistema es capaz de recuperar o capturar</center> 

    * Empleado habitualmente para medir la calidad de un resumen y en traducción automática.
    * Especialmente útil con resúmenes, donde es más importante evaluar en dichos casos el número de palabras que el modelo es capaz de recordar.

<!-- ROUGE (Recall-Oriented Understudy for Gisting Evaluation) difiere de la medida BLEU en tanto que mide la memoria, esto es, cuánto del documento de referencia el 
sistema es capaz de recuperar o capturar. Se emplea habitualmente para medir la calidad de un resumen, así como en tareas de 
traducción automática. Sin embargo, dado que mide la memoria es utilizada principalmente de cara a tareas de resumen, dado que resulta más importante evaluar en dichos casos el número de palabras que
el modelo es capaz de recordar. -->

--- 

## Métricas utilizadas: ROUGE

Variaciones dentro de ROUGE, todas comparando el sistema con los documentos de referencia:
    * ROUGE-N: Superposición de ngramas.
        * ROUGE-1 contempla el solapamiento de los unigramas, esto es, las palabras individuales.
        * ROUGE-2 trabaja con digramas.
    * ROUGE-L: Recurre al concepto de Mayor Subsecuencia Común (LCS).
    * ROUGE-W: Versión ponderada de ROUGE-L.
    * ROUGE-S: Trabaja con digramas con salto, es decir, parejas de palabras respetando el orden.
    * ROUGE-SU: Combina los digramas de salto con relaciones entre unigramas.

<center>
    <img src="images/ROUGE.png" alt="Ejemplo ROUGE-L" class="center">
    <div><span style="font-style: italic; font-size: 20;">Muestra para calcular la métrica ROUGE.</span></div>
</center>

---

# Inclusión de SLP en el marco NLP

---

## Inclusión de SLP en el marco NLP

Aunque las lenguas de signos y las habladas difieren en cuanto a la modalidad, dado que ambas expresan los niveles linguísticos propios de los lenguajes naturales, las teorías fundamentales en NLP pueden y deben extenderse a las lenguas de signos.

* <span style="color: rgb(163, 42, 42);">Herramientas de NLP</span>: 
	* Tokenizadores.
	* Analizadores sintácticos.
	* Reconocimiento de entidades nombradas.
	* Resolución de correferencia.

--- 

## Inclusión de SLP en el marco NLP

* <span style="color: rgb(163, 42, 42);">Tokenizadores</span>
	* La gran mayoría de los métodos de PLN requieren una entrada  discreta (token).
	* Necesidad de herramientas de tokenización adecuadas que mapeen los vídeos de las lenguas de signos a una representación discreta y precisa con una mínima pérdida de información.
	* Los sistemas y conjuntos de datos de PLN existentes suelen utilizar glosas como unidades léxicas discretas. Problemas:
		* Insuficientes para las construcciones espaciales de la lengua de signos.
		* Glosas específicas de cada lengua, no estandarizadas.


<span style="font-weight: bold;"> Preguntas abiertas:</span>

- ¿Cómo definimos las unidades léxicas en las lenguas de signos? 
- ¿Las unidades fonológicas de las lenguas de signos pueden asignarse a unidades léxicas?
- ¿Pueden las técnicas utilizadas en *Speech Recognition* ser aplicadas las lenguas de signos?

--- 

## Inclusión de SLP en el marco NLP

* <span style="color: rgb(163, 42, 42);">Analizadores sintácticos</span>
	* El etiquetado de partes del discurso (PDD) y el análisis sintáctico son fundamentales para comprender el significado de las palabras en contexto.
	* Se debe definir en qué medida el etiquetado PDD y el análisis sintáctico para los idiomas hablados también se generalizan a los lenguajes de signos.

<span style="font-weight: bold;"> Preguntas abiertas:</span>

- ¿Existen teorías lingüísticas para diseñar características y reglas que realicen estas tareas? 
- ¿Cómo se expresan las características morfológicas?
- ¿Necesitamos un nuevo conjunto de etiquetas y PDD para los lenguajes de signos? 

--- 

## Inclusión de SLP en el marco NLP

* <span style="color: rgb(163, 42, 42);">Reconocimiento de entidades nombradas</span>
	* Las entidades nombradas en los lenguajes de señas pueden producirse mediante una secuencia de deletreo manual, un signo o incluso mediante la pronunciación del nombre mientras que la referencia es señalanda..
	* Un detalle importante: **La Anonimización**.

<span style="font-weight: bold;"> Preguntas abiertas:</span>

- ¿Cuáles son los marcadores visuales de las entidades nombradas?
- ¿Cómo se presentan y referencian?
- ¿Cómo se establecen las relaciones entre ellos?

--- 

## Hacia una PNL lingüísticamente informada y multimodal

Es necesaria la colaboración de las comunidades de investigación multimodal y de SLP para desarrollar modelos potentes de SLP apoyados herramientas básicas de PLN como las comentadas, todo ello mientras se procesa y relaciona la información procedente de las modalidades lingüística y visual

El SLP está especialmente sujeta a tres de los principales retos técnicos en el aprendizaje automático multimodal:

<span style="font-weight: bold;"> Puntos clave:</span>

* <span style="color: rgb(163, 42, 42);">Traducción</span>: ¿cómo pasar la información visual-gestual a/desde la información oral-textual?
* <span style="color: rgb(163, 42, 42);">Alineación</span>: ¿cómo relacionar las unidades de la lengua de signos con las de la lengua hablada?
* <span style="color: rgb(163, 42, 42);">Co-aprendizaje</span>: ¿cómo aprovechar el conocimiento de la lengua hablada en la lengua de signos?

---

# Conclusiones

--- 

* El lenguaje de signos es el método de comunicación principal para las personas sordas, por ello es relevante garantizar la inclusión tecnológica y social se desarrollen las tecnologías necesarias. 

* Lingüísticamente, los lenguajes de signos,  como lenguajes naturales, cuentan con muchas similitudes con los lenguajes orales, aunque mediante el uso del visual e incorporando particularidades propias de los lenguajes: Simultaneidad, Referencias, Deletreo, etc.

* El procesamiento del Lenguaje de Signos inmiscuye tres aspectos principales:
    - <span style="color: rgb(163, 42, 42);">Reconocimiento</span>: con múltiples tecnologías y enfoques destacando el papel del DeepLearning tanto en CSLR (2D y 3D) como en ISLR que, a pesar de ser la aproximación más popular, no es la más adecuada.
    - <span style="color: rgb(163, 42, 42);">Traducción</span>: el core central del procesamiento, en el que se entrelazan dos de los principales ámbitos de la IA actual: el Procesamiento del Lenguaje Natural y la Visión por Computador. Aunque con importantes avances, se necesita de una mayor cooperación y interés investigador para el desarrollo de este ámbito.

---

* El procesamiento del Lenguaje de Signos inmiscuye tres aspectos principales: 
    - <span style="color: rgb(163, 42, 42);">Generación</span>: adoptan avatares 3D y arquitecturas de generación de video. Sin embargo, hasta el momento se requerían de generación manual, difícil y costosa. Sin embargo los avances recientes en este ámbito, el auge de AR-VR auguran importantes avances en los próximos años.

* Aunque existen diferentes conjuntos de datos, la excasez de los mismos, su reducido tamaño, las grandes limitaciones de uso y las grandes variaciones en los contenidos de los mismos (glosas, videos, alineación de textos, ...), y la anonimización, dificultan las tareas de aprendizaje. 

* Lineas futuras: Fusión de información multicanal, aprendizaje de patrones espacio-temporales (GNN), aumento del conocimiento específico del dominio, lidiar con la excasez de datos. Y sobre todo:

<center style="color: rgb(163, 42, 42);">
    ESTUDIOS MULTIDISCIPLINARES Y COOPERACIÓN
</center>


---





<center style="margin-top: 350px;">
    <span style="font-weight: bolder;">Procesamiento del Lenguaje de Signos</span><br>
    <span style="font-weight: lighter; font-size: 35;">Fundamentos, tecnologías y retos actuales</span>
    </center>
    
    <center style="margin-top: 200px;">
    <span style="font-variant: small-caps; font-size: 30; color: rgb(163, 42, 42);">Claudio Bustamente, Julián M. Galindo, Víctor Ramos, J. Antonio Rodríguez</span><br>
    </center>
    
    <center style="margin-top: 100px;">
        <span style="font-style: italic; font-size: 30;">Fuente Ppal: [Including Signed Languages in Natural Language Processing](https://aclanthology.org/2021.acl-long.570) (Yin et al., ACL 2021) </span><br>
        </center>

<!-- Markdeep slides stuff -->
<script>
    markdeepSlidesOptions = {
        aspectRatio: 16 / 9,
        theme: 'simple',
        fontSize: 22,
        diagramZoom: 1.0,
        totalSlideNumber: false,
        progressBar: true,
        breakOnHeadings: false,
        slideChangeHook: (oldSlide, newSlide) => {},
        modeChangeHook: (newMode) => {}
    };
</script>
<link rel="stylesheet" href="markdeep-slides/lib/markdeep-relative-sizes/1.11/relativize.css">
<link rel="stylesheet" href="markdeep-slides/markdeep-slides.css">
<script src="markdeep-slides/markdeep-slides.js"></script>

<!-- Markdeep stuff -->
<script>
    markdeepOptions = {
        tocStyle: 'none',
        detectMath: true,
        onLoad: function() {
            initSlides();
        }
    };
</script>
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep-slides/lib/markdeep/1.11/markdeep.min.js" charset="utf-8"></script>
<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
